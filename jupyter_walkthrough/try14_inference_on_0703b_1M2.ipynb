{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c8fd92-6fdc-4c9b-8049-09c3480ac567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil\n",
    "import argparse\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e8d288-a9b0-42d6-8aaf-c8d2e9c7baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282d4d4f-fa59-4179-b9a1-8fb522b7949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt_val_path = r'.\\preprocessed_data\\Ego4D_final_v6\\val.txt'\n",
    "val_uids = []\n",
    "with open(split_txt_val_path) as file:\n",
    "    for line in file:\n",
    "        # print(line.split('|')[0])\n",
    "        val_uids.append(line.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b8f4b3-f23b-438f-bcca-128f0fb9d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772\n"
     ]
    }
   ],
   "source": [
    "print(len(val_uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0cd78d-5fa1-4f76-a0d2-48d7aa20ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import get_model, get_vocoder, get_param_num, vocoder_infer\n",
    "from utils.tools import to_device, log, synth_one_sample, expand, plot_mel\n",
    "from model import FastSpeech2Loss\n",
    "from dataset import Dataset\n",
    "# from utils.auto_tqdm import tqdm\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df4400a-5dc8-4bbd-bc33-a2abdbc20379",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc1e0e1-6a63-488b-8db4-6c012d07de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--restore_step\", type=int, default=0)\n",
    "parser.add_argument(\n",
    "    \"-p\",\n",
    "    \"--preprocess_config\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"path to preprocess.yaml\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-m\", \"--model_config\", type=str, required=True, help=\"path to model.yaml\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-t\", \"--train_config\", type=str, required=True, help=\"path to train.yaml\"\n",
    ")\n",
    "\n",
    "argString = '-p ./config/Ego4D_final_v6/0703b_preprocess.yaml -m ./config/Ego4D_final_v6/0703b_model.yaml -t ./config/Ego4D_final_v6/0703b_train.yaml'\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(argString.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd246a8-1876-4adc-bfe3-d71e0fa505ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(restore_step=0, preprocess_config='./config/Ego4D_final_v6/0703b_preprocess.yaml', model_config='./config/Ego4D_final_v6/0703b_model.yaml', train_config='./config/Ego4D_final_v6/0703b_train.yaml')\n",
      "Prepare training ...\n"
     ]
    }
   ],
   "source": [
    "pprint(args)\n",
    "# Read Config\n",
    "preprocess_config = yaml.load(\n",
    "    open(args.preprocess_config, \"r\"), Loader=yaml.FullLoader\n",
    ")\n",
    "model_config = yaml.load(open(args.model_config, \"r\"), Loader=yaml.FullLoader)\n",
    "train_config = yaml.load(open(args.train_config, \"r\"), Loader=yaml.FullLoader)\n",
    "configs = (preprocess_config, model_config, train_config)\n",
    "print(\"Prepare training ...\")\n",
    "\n",
    "preprocess_config, model_config, train_config = configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71c6ee8-4c95-48b5-9989-5f1766ae5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = r'./output/0703b/ckpt/Ego4D_final_v6/1200000.pth.tar'\n",
    "ckpt = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9154f9-7141-4547-95a7-1d1934720805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Not using speaker embeddings.\n",
      "False\n",
      "None\n",
      "Number of FastSpeech2 Parameters: 35159745\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "model, optimizer = get_model(args, configs, device, train=True)\n",
    "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "num_param = get_param_num(model)\n",
    "Loss = FastSpeech2Loss(preprocess_config, model_config).to(device)\n",
    "print(\"Number of FastSpeech2 Parameters:\", num_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6af19e-bc86-4feb-8a06-7a5886d215d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load vocoder\n",
    "vocoder = get_vocoder(model_config, device)\n",
    "step = args.restore_step + 1\n",
    "model.eval()\n",
    "print()\n",
    "dataset = Dataset(\n",
    "    \"val.txt\", 'val', preprocess_config, train_config, sort=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cf4906f-8cc3-459e-a23b-7bac97832235",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_config[\"optimizer\"][\"batch_size\"]\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcade0b8-7b54-4616-ac7c-0fc9b36e0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "    )\n",
    "# Get loss function\n",
    "Loss = FastSpeech2Loss(preprocess_config, model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a94adb6-831d-4c53-ba37-61a31a9d0be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/0703b/result/Ego4D_final_v6\\\\plots'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(train_config['path']['result_path'], 'plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c693e09-3570-495c-9b6c-de66799dab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => batch:\n",
    "# return (\n",
    "#     ids,\n",
    "#     raw_texts,\n",
    "#     speakers,\n",
    "#     texts,\n",
    "#     text_lens,\n",
    "#     max(text_lens),\n",
    "#     mels,\n",
    "#     mel_lens,\n",
    "#     max(mel_lens),\n",
    "#     pitches,\n",
    "#     energies,\n",
    "#     durations,\n",
    "#     speaker_embeddings,\n",
    "# )\n",
    "# [12] 对应speaker embedding\n",
    "\n",
    "\n",
    "# => model output / prediction\n",
    "# return (\n",
    "#     output,\n",
    "#     postnet_output,\n",
    "#     p_predictions,\n",
    "#     e_predictions,\n",
    "#     log_d_predictions,\n",
    "#     d_rounded,\n",
    "#     src_masks,\n",
    "#     mel_masks,\n",
    "#     src_lens,\n",
    "#     mel_lens,\n",
    "# )\n",
    "output_plot_path = os.path.join(train_config['path']['result_path'], 'plot')\n",
    "output_mel_syn_path = os.path.join(train_config['path']['result_path'], 'mel', 'syn')\n",
    "output_mel_gt_path = os.path.join(train_config['path']['result_path'], 'mel', 'gt')\n",
    "output_wav_syn_path = os.path.join(train_config['path']['result_path'], 'wav', 'synthesized')\n",
    "output_wav_rec_path = os.path.join(train_config['path']['result_path'], 'wav', 'reconstructed')\n",
    "os.makedirs(output_plot_path, exist_ok=True)\n",
    "os.makedirs(output_mel_syn_path, exist_ok=True)\n",
    "os.makedirs(output_mel_gt_path, exist_ok=True)\n",
    "os.makedirs(output_wav_syn_path, exist_ok=True)\n",
    "os.makedirs(output_wav_rec_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1d8595-0c2a-49f8-a682-39451980f00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2605527ff534ddb8c1e2715e984baef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batchs in tqdm(loader):\n",
    "    for targets in batchs:\n",
    "        targets = to_device(targets, device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(*(targets[2:]))\n",
    "        basenames = targets[0]\n",
    "        for i in range(len(predictions[0])):\n",
    "            basename = basenames[i]\n",
    "            src_len = predictions[8][i].item()\n",
    "            mel_len = predictions[9][i].item()\n",
    "            mel_prediction = predictions[1][i, :mel_len].detach().transpose(0, 1)\n",
    "            mel_target = targets[6][i, :mel_len].detach().transpose(0, 1)\n",
    "\n",
    "            torch.save(mel_prediction.cpu(), os.path.join(output_mel_syn_path, f\"{basename}.pt\"))\n",
    "            torch.save(mel_target.cpu(), os.path.join(output_mel_gt_path, f\"{basename}.pt\"))\n",
    "            \n",
    "            \n",
    "            duration = predictions[5][i, :src_len].detach().cpu().numpy()\n",
    "            if preprocess_config[\"preprocessing\"][\"pitch\"][\"feature\"] == \"phoneme_level\":\n",
    "                pitch = predictions[2][i, :src_len].detach().cpu().numpy()\n",
    "                pitch = expand(pitch, duration)\n",
    "            else:\n",
    "                pitch = predictions[2][i, :mel_len].detach().cpu().numpy()\n",
    "            if preprocess_config[\"preprocessing\"][\"energy\"][\"feature\"] == \"phoneme_level\":\n",
    "                energy = predictions[3][i, :src_len].detach().cpu().numpy()\n",
    "                energy = expand(energy, duration)\n",
    "            else:\n",
    "                energy = predictions[3][i, :mel_len].detach().cpu().numpy()\n",
    "\n",
    "            with open(os.path.join(preprocess_config[\"path\"][\"preprocessed_path\"], \n",
    "                                   \"stats.json\")) as f:\n",
    "                stats = json.load(f)\n",
    "                stats = stats[\"pitch\"] + stats[\"energy\"][:2]\n",
    "                                       \n",
    "            fig = plot_mel(\n",
    "                [\n",
    "                    (mel_prediction.cpu().numpy(), pitch, energy),\n",
    "                    (mel_target.cpu().numpy(), pitch, energy),\n",
    "                ],\n",
    "                stats,\n",
    "                [\"Synthetized Spectrogram\", \"Ground-Truth Spectrogram\"],\n",
    "            )\n",
    "            ### TODO: change to svg\n",
    "            plt.savefig(os.path.join(output_plot_path, f\"{basename}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # from .model import vocoder_infer\n",
    "\n",
    "        mel_predictions = predictions[1].transpose(1, 2)\n",
    "        mel_targets = targets[6].transpose(1, 2)\n",
    "        \n",
    "        lengths = predictions[9] * preprocess_config[\"preprocessing\"][\"stft\"][\"hop_length\"]\n",
    "        wav_predictions = vocoder_infer(\n",
    "            mel_predictions, vocoder, model_config, preprocess_config, lengths=lengths\n",
    "        )\n",
    "        wav_targets = vocoder_infer(\n",
    "        mel_targets, vocoder, model_config, preprocess_config, lengths=lengths\n",
    "    )\n",
    "    \n",
    "        sampling_rate = preprocess_config[\"preprocessing\"][\"audio\"][\"sampling_rate\"]\n",
    "        for wav, basename in zip(wav_predictions, basenames):\n",
    "            wavfile.write(os.path.join(output_wav_syn_path, f\"{basename}.wav\"), sampling_rate, wav)\n",
    "        for wav, basename in zip(wav_targets, basenames):\n",
    "            wavfile.write(os.path.join(output_wav_rec_path, f\"{basename}.wav\"), sampling_rate, wav)\n",
    "\n",
    "        \n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f4c89-f9cb-4be0-9afe-49d61423645a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa5bba-c3f6-4ad0-a6d5-9ec77990dfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4fade-5ca6-4c3e-a532-9abcc4d02bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27534501-957f-4df6-9b5e-e4762d85d96d",
   "metadata": {},
   "source": [
    "# MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5024f09b-2780-4c5f-9489-64202ff55960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil\n",
    "import os.path as op\n",
    "import argparse\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import os.path as op\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import argparse\n",
    "import fnmatch\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import librosa\n",
    "import pysptk\n",
    "import pyworld as pw\n",
    "import soundfile as sf\n",
    "from fastdtw import fastdtw\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d18e754-93b1-47f9-a8dc-ce473582065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt_val_path = r'.\\preprocessed_data\\Ego4D_final_v6\\val.txt'\n",
    "val_uids = []\n",
    "with open(split_txt_val_path) as file:\n",
    "    for line in file:\n",
    "        # print(line.split('|')[0])\n",
    "        val_uids.append(line.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67d5a21-9968-4178-b2c1-6d7feffddc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11188da4-e0ec-4562-9233-a13945922a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_folder = r'.\\output\\0703b\\result\\Ego4D_final_v6\\wav\\reconstructed'\n",
    "syn_folder = r'.\\output\\0703b\\result\\Ego4D_final_v6\\wav\\synthesized'\n",
    "gt_folder = r'.\\raw_data\\Ego4D_final_v6\\val\\Ego4D_final_v6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b5f53b4-24d1-4b76-916c-0fbb01d32a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "melkwargs = {\n",
    "    \"n_fft\": int(0.05 * sr), \"win_length\": int(0.05 * sr),\n",
    "    \"hop_length\": int(0.0125 * sr), \"f_min\": 20,\n",
    "    \"n_mels\": 80, \"window_fn\": torch.hann_window\n",
    "}\n",
    "mfcc_fn = torchaudio.transforms.MFCC(\n",
    "    sr, n_mfcc=13, log_mels=True, melkwargs=melkwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40484578-7b33-443e-9dfd-510d1132ce63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946936645307403fb3122ebbe4f14ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 11s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uids = []\n",
    "MCDs_recon = []\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    wav_1, sr = torchaudio.load(op.join(recon_folder, f\"{uid}.wav\"))\n",
    "    wav_2, sr = torchaudio.load(op.join(syn_folder, f\"{uid}.wav\"))\n",
    "    wav_1 = wav_1.squeeze()\n",
    "    wav_2 = wav_2.squeeze()\n",
    "    mel_1 = mfcc_fn(wav_1).T.numpy()\n",
    "    mel_2 = mfcc_fn(wav_2).T.numpy()\n",
    "    # DTW\n",
    "    _, path = fastdtw(mel_2, mel_1, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    mel_2 = mel_2[twf[0]]\n",
    "    mel_1 = mel_1[twf[1]]\n",
    "    # We sum the squared differences over the first K MFCCs, skipping ct,0\n",
    "    mel_1 = mel_1[:, 1:]\n",
    "    mel_2 = mel_2[:, 1:]\n",
    "    result = (((mel_1 - mel_2) ** 2).sum(axis=1)**0.5).mean()\n",
    "    MCDs_recon.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2395ac1-08dd-4916-bcaf-dd332fa1e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ccadd506834f19a907c4185e371e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 45s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uids = []\n",
    "MCDs_gt = []\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    wav_1, sr = torchaudio.load(op.join(gt_folder, f\"{uid}.wav\"))\n",
    "    wav_2, sr = torchaudio.load(op.join(syn_folder, f\"{uid}.wav\"))\n",
    "    wav_1 = wav_1.squeeze()\n",
    "    wav_2 = wav_2.squeeze()\n",
    "    mel_1 = mfcc_fn(wav_1).T.numpy()\n",
    "    mel_2 = mfcc_fn(wav_2).T.numpy()\n",
    "    # DTW\n",
    "    _, path = fastdtw(mel_2, mel_1, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    mel_2 = mel_2[twf[0]]\n",
    "    mel_1 = mel_1[twf[1]]\n",
    "    # We sum the squared differences over the first K MFCCs, skipping ct,0\n",
    "    mel_1 = mel_1[:, 1:]\n",
    "    mel_2 = mel_2[:, 1:]\n",
    "    result = (((mel_1 - mel_2) ** 2).sum(axis=1)**0.5).mean()\n",
    "    MCDs_gt.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed80f2b-cddf-4113-a785-b0d8ab18ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_mcd_df = pd.DataFrame({\n",
    "    'uid': uids,\n",
    "    'MCD_recon': MCDs_recon,\n",
    "    'MCD_gt': MCDs_gt,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ecfcd55-3d94-4e77-bc78-8d28a6a6ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_mcd_df.to_csv(r\".\\jupyter_walkthrough\\metrics\\MCD_0703b_1M2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd15d4af-ad70-4f3d-bdba-e2eda31debcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDs_recon mean on 0703b_1M2: 13.177790641784668\n",
      "MCDs_recon std on 0703b_1M2: 2.5031161308288574\n",
      "MCDs_gt mean on 0703b_1M2: 14.175084114074707\n",
      "MCDs_gt std on 0703b_1M2: 2.488023281097412\n"
     ]
    }
   ],
   "source": [
    "print(f\"MCDs_recon mean on 0703b_1M2: {torch.tensor(MCDs_recon).mean()}\")\n",
    "print(f\"MCDs_recon std on 0703b_1M2: {torch.tensor(MCDs_recon).std()}\")\n",
    "\n",
    "print(f\"MCDs_gt mean on 0703b_1M2: {torch.tensor(MCDs_gt).mean()}\")\n",
    "print(f\"MCDs_gt std on 0703b_1M2: {torch.tensor(MCDs_gt).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6660d626-652a-4978-bdeb-43d2426457de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56d0a0-d57f-4263-87be-0ac251297083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27d164-894c-407a-abfb-2c163684941e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6588b-2819-49f2-8b6e-8be7ad04730f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e40cc-bf78-4f51-8196-ffb20ccfd7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e78b82-4120-4618-afe3-a5b8e5fad8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580da8ac-333d-4bb7-8ad4-f788a01ed4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d11476-c647-4d02-ab20-65c4b69bfa23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d7a1b-c7e6-486b-b344-731b7e8d163b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c07ee-b3ea-40e1-a98b-764fd13c3aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615ce46-99f3-48c3-b239-f6db770d4c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761d38e-06e8-41d5-b2de-d8b8e6ed41ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab41eb-d9ee-4332-9d6c-e06094710074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a344d-0130-4cfb-8238-de058ee16c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044919ee-4da3-4e56-80ed-a9e13a38655a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7e580-a086-425b-bac5-d8b4c17fbca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94afb4-303b-47c5-a691-358201ccd9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dab537-b68c-476b-94ec-412efc77e47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f959823-fede-4aa9-9679-a9bd967346ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1184944-73e6-40d8-b0c9-4af04ffa3c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84e1c3-7fdb-4139-968a-ff73e44f54f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6c47d-a519-462f-b768-2844892f895f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7cff073-0299-41c7-bc8f-d9ebfe1ddfce",
   "metadata": {},
   "source": [
    "# log f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfcb4cb9-17c3-49a1-a65b-0bf2bdee39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/espnet/espnet/blob/3e0dad524d62ccd45e067e9b36049f2214ea972a/egs2/TEMPLATE/asr1/pyscripts/utils/evaluate_f0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3996818b-4c8d-4ef8-ad18-ac90d9f4fa21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def world_extract(\n",
    "    x: np.ndarray,\n",
    "    fs: int,\n",
    "    f0min: int = 40,\n",
    "    f0max: int = 800,\n",
    "    n_fft: int = 512,\n",
    "    n_shift: int = 256,\n",
    "    mcep_dim: int = 25,\n",
    "    mcep_alpha: float = 0.41,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Extract World-based acoustic features.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): 1D waveform array.\n",
    "        fs (int): Minimum f0 value (default=40).\n",
    "        f0 (int): Maximum f0 value (default=800).\n",
    "        n_shift (int): Shift length in point (default=256).\n",
    "        n_fft (int): FFT length in point (default=512).\n",
    "        n_shift (int): Shift length in point (default=256).\n",
    "        mcep_dim (int): Dimension of mel-cepstrum (default=25).\n",
    "        mcep_alpha (float): All pass filter coefficient (default=0.41).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Mel-cepstrum with the size (N, n_fft).\n",
    "        ndarray: F0 sequence (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # extract features\n",
    "    x = x.astype(np.float64)\n",
    "    f0, time_axis = pw.harvest(\n",
    "        x,\n",
    "        fs,\n",
    "        f0_floor=f0min,\n",
    "        f0_ceil=f0max,\n",
    "        frame_period=n_shift / fs * 1000,\n",
    "    )\n",
    "    sp = pw.cheaptrick(x, f0, time_axis, fs, fft_size=n_fft)\n",
    "    if mcep_dim is None or mcep_alpha is None:\n",
    "        mcep_dim, mcep_alpha = _get_best_mcep_params(fs)\n",
    "    mcep = pysptk.sp2mc(sp, mcep_dim, mcep_alpha)\n",
    "\n",
    "    return mcep, f0\n",
    "\n",
    "\n",
    "def _get_basename(path: str) -> str:\n",
    "    return os.path.splitext(os.path.split(path)[-1])[0]\n",
    "\n",
    "\n",
    "def _get_best_mcep_params(fs: int) -> Tuple[int, float]:\n",
    "    if fs == 16000:\n",
    "        return 23, 0.42\n",
    "    elif fs == 22050:\n",
    "        return 34, 0.45\n",
    "    elif fs == 24000:\n",
    "        return 34, 0.46\n",
    "    elif fs == 44100:\n",
    "        return 39, 0.53\n",
    "    elif fs == 48000:\n",
    "        return 39, 0.55\n",
    "    else:\n",
    "        raise ValueError(f\"Not found the setting for {fs}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b54a4f44-0aeb-4177-a827-6bbf0effec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909ba66d76cb40e3a4f27397d8aa2bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip uid 342edcf2-1150-42a0-af79-030571c0996d. len == 0.\n",
      "Skip uid 2ff974ac-b0f1-4611-8c9f-61c216a8ba96. len == 0.\n",
      "Skip uid 959dcb2b-4291-45b4-aa24-dc144de6fc1a. len == 0.\n",
      "Skip uid 94ab3c42-86a9-427c-9dc7-9d3583836f89. len == 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2846: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "D:\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2705: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "D:\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2705: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip uid d7c942a6-bfd3-4ff2-9926-88fafe78781b. len == 0.\n",
      "Skip uid 9f56d2e9-8536-4ce4-878e-e31f5c64345a. len == 0.\n",
      "Skip uid 0d885f9d-8786-40d2-ab4b-d6874b5c6507. len == 0.\n",
      "Skip uid dc0bb287-5310-44a9-b491-b195d98fd53e. len == 0.\n"
     ]
    }
   ],
   "source": [
    "uids = []\n",
    "logf0_rmses_recon = []\n",
    "logf0_corrs_recon = []\n",
    "\n",
    "for uid in tqdm(val_uids):\n",
    "    \n",
    "    # load wav file as int16\n",
    "    gen_x, gen_fs = sf.read(op.join(syn_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    gt_x, gt_fs = sf.read(op.join(recon_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    fs = gen_fs\n",
    "    # extract ground truth and converted features\n",
    "    gen_mcep, gen_f0 = world_extract(\n",
    "        x=gen_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    gt_mcep, gt_f0 = world_extract(\n",
    "        x=gt_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    \n",
    "    # DTW\n",
    "    _, path = fastdtw(gen_mcep, gt_mcep, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    gen_f0_dtw = gen_f0[twf[0]]\n",
    "    gt_f0_dtw = gt_f0[twf[1]]\n",
    "    \n",
    "    # Get voiced part\n",
    "    nonzero_idxs = np.where((gen_f0_dtw != 0) & (gt_f0_dtw != 0))[0]\n",
    "    eps = 1e-7\n",
    "    gen_f0_dtw_voiced = np.log(gen_f0_dtw[nonzero_idxs] + eps)\n",
    "    gt_f0_dtw_voiced = np.log(gt_f0_dtw[nonzero_idxs] + eps)\n",
    "\n",
    "    if len(gen_f0_dtw_voiced) == 0 or len(gt_f0_dtw_voiced) == 0:\n",
    "        print(f\"Skip uid {uid}. len == 0.\")\n",
    "        continue\n",
    "\n",
    "    # log F0 RMSE\n",
    "    log_f0_rmse = np.sqrt(np.mean((gen_f0_dtw_voiced - gt_f0_dtw_voiced) ** 2))\n",
    "    # print(f\"{uid} {log_f0_rmse:.4f}\")\n",
    "\n",
    "    # log F0 corr\n",
    "    log_f0_corr = np.corrcoef(gen_f0_dtw_voiced, gt_f0_dtw_voiced)[0][1]\n",
    "    # print(f\"{uid} {log_f0_corr:.4f}\")\n",
    "    uids.append(uid)\n",
    "    logf0_rmses_recon.append(log_f0_rmse)\n",
    "    logf0_corrs_recon.append(log_f0_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa1413e0-a16c-4e9a-92fb-d9c71351ddc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m v6_logf0_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogf0_rmse_recon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogf0_rmses_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogf0_corr_recon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogf0_corrs_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'logf0_rmse_gt': logf0_rmses_gt,\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'logf0_corr_gt': logf0_corrs_gt,\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m v6_logf0_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjupyter_walkthrough\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlogF0_0703b_1M2_recon.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "v6_logf0_df = pd.DataFrame({\n",
    "    'uid': uids,\n",
    "    'logf0_rmse_recon': logf0_rmses_recon,\n",
    "    'logf0_corr_recon': logf0_corrs_recon,\n",
    "    # 'logf0_rmse_gt': logf0_rmses_gt,\n",
    "    # 'logf0_corr_gt': logf0_corrs_gt,\n",
    "})\n",
    "v6_logf0_df.to_csv(r\".\\jupyter_walkthrough\\metrics\\logF0_0703b_1M2_recon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a7f3781-5c03-437d-936b-e81363e68884",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_logf0_df = v6_logf0_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecf0615e-de0a-40e4-97bc-5ce27561eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logf0_rmse_recon mean on 0703a_1M2: 0.281800061308213\n",
      "logf0_rmse_recon std on 0703a_1M2: 0.21063260145936688\n",
      "logf0_corr_recon mean on 0703a_1M2: 0.3964503656060779\n",
      "logf0_corr_recon std on 0703a_1M2: 0.40082667019104107\n"
     ]
    }
   ],
   "source": [
    "print(f\"logf0_rmse_recon mean on 0703a_1M2: {v6_logf0_df['logf0_rmse_recon'].values.mean()}\")\n",
    "print(f\"logf0_rmse_recon std on 0703a_1M2: {v6_logf0_df['logf0_rmse_recon'].values.std()}\")\n",
    "print(f\"logf0_corr_recon mean on 0703a_1M2: {v6_logf0_df['logf0_corr_recon'].values.mean()}\")\n",
    "print(f\"logf0_corr_recon std on 0703a_1M2: {v6_logf0_df['logf0_corr_recon'].values.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "190efe74-b356-4c37-b679-6fc0d8227dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5649a07ffc8a4586b38eb034177b7e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "D:\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip uid 2ff974ac-b0f1-4611-8c9f-61c216a8ba96. len == 0.\n",
      "Skip uid 2ed7e799-e015-4652-bdb1-96b6ecb9c33a. len == 0.\n",
      "Skip uid 48c252f2-5e53-426d-b275-2974976ce16d. len == 0.\n",
      "Skip uid b3f48076-f0d8-4209-8bc1-9ac3d0d76e60. len == 0.\n",
      "Skip uid 76dcc2bc-871e-4ba6-8b8c-5a4cc6a42c4d. len == 0.\n",
      "Skip uid c40778c5-b585-4897-94ff-6a35edf19add. len == 0.\n",
      "Skip uid d7c942a6-bfd3-4ff2-9926-88fafe78781b. len == 0.\n",
      "Skip uid b13f3ab6-fb65-4ae2-9929-4f06d0d58951. len == 0.\n",
      "Skip uid 934d0029-f16a-4001-9dbc-37924272f3b5. len == 0.\n",
      "Skip uid 346a8e85-6aff-43d9-87c1-5884a4466686. len == 0.\n"
     ]
    }
   ],
   "source": [
    "uids = []\n",
    "logf0_rmses_gt = []\n",
    "logf0_corrs_gt = []\n",
    "\n",
    "for uid in tqdm(val_uids):\n",
    "    \n",
    "    # load wav file as int16\n",
    "    gen_x, gen_fs = sf.read(op.join(syn_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    gt_x, gt_fs = sf.read(op.join(gt_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    fs = gen_fs\n",
    "    # extract ground truth and converted features\n",
    "    gen_mcep, gen_f0 = world_extract(\n",
    "        x=gen_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    gt_mcep, gt_f0 = world_extract(\n",
    "        x=gt_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    \n",
    "    # DTW\n",
    "    _, path = fastdtw(gen_mcep, gt_mcep, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    gen_f0_dtw = gen_f0[twf[0]]\n",
    "    gt_f0_dtw = gt_f0[twf[1]]\n",
    "    \n",
    "    # Get voiced part\n",
    "    nonzero_idxs = np.where((gen_f0_dtw != 0) & (gt_f0_dtw != 0))[0]\n",
    "    eps = 1e-7\n",
    "    gen_f0_dtw_voiced = np.log(gen_f0_dtw[nonzero_idxs] + eps)\n",
    "    gt_f0_dtw_voiced = np.log(gt_f0_dtw[nonzero_idxs] + eps)\n",
    "\n",
    "    if len(gen_f0_dtw_voiced) == 0 or len(gt_f0_dtw_voiced) == 0:\n",
    "        print(f\"Skip uid {uid}. len == 0.\")\n",
    "        continue\n",
    "\n",
    "    # log F0 RMSE\n",
    "    log_f0_rmse = np.sqrt(np.mean((gen_f0_dtw_voiced - gt_f0_dtw_voiced) ** 2))\n",
    "    # print(f\"{uid} {log_f0_rmse:.4f}\")\n",
    "\n",
    "    # log F0 corr\n",
    "    log_f0_corr = np.corrcoef(gen_f0_dtw_voiced, gt_f0_dtw_voiced)[0][1]\n",
    "    # print(f\"{uid} {log_f0_corr:.4f}\")\n",
    "    uids.append(uid)\n",
    "    logf0_rmses_gt.append(log_f0_rmse)\n",
    "    logf0_corrs_gt.append(log_f0_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82dc55a3-f51d-49f9-b304-a4df26da4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_logf0_df = pd.DataFrame({\n",
    "    'uid': uids,\n",
    "    # 'logf0_rmse_recon': logf0_rmses_recon,\n",
    "    # 'logf0_corr_recon': logf0_corrs_recon,\n",
    "    'logf0_rmse_gt': logf0_rmses_gt,\n",
    "    'logf0_corr_gt': logf0_corrs_gt,\n",
    "})\n",
    "v6_logf0_df.to_csv(r\".\\jupyter_walkthrough\\metrics\\logF0_0703b_1M2_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae9c81c0-b7d6-4187-bded-eaec9eaf1c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logf0_rmse_recon mean on 0703b_1M2: 0.28251933401716595\n",
      "logf0_rmse_recon std on 0703b_1M2: 0.21249448804620955\n",
      "logf0_corr_recon mean on 0703b_1M2: 0.3964503656060779\n",
      "logf0_corr_recon std on 0703b_1M2: 0.40082667019104107\n",
      "logf0_rmse_gt mean on 0703b_1M2: 0.3133671631279824\n",
      "logf0_rmse_gt std on 0703b_1M2: 0.23074303607466276\n",
      "logf0_corr_gt mean on 0703b_1M2: 0.3245314250353599\n",
      "logf0_corr_gt std on 0703b_1M2: 0.39623624855837947\n"
     ]
    }
   ],
   "source": [
    "logf0_rmses_recon_array = np.array(logf0_rmses_recon)[~np.isnan(np.array(logf0_rmses_recon))]\n",
    "logf0_corrs_recon_array = np.array(logf0_corrs_recon)[~np.isnan(np.array(logf0_corrs_recon))]\n",
    "\n",
    "print(f\"logf0_rmse_recon mean on 0703b_1M2: {logf0_rmses_recon_array.mean()}\")\n",
    "print(f\"logf0_rmse_recon std on 0703b_1M2: {logf0_rmses_recon_array.std()}\")\n",
    "print(f\"logf0_corr_recon mean on 0703b_1M2: {logf0_corrs_recon_array.mean()}\")\n",
    "print(f\"logf0_corr_recon std on 0703b_1M2: {logf0_corrs_recon_array.std()}\")\n",
    "\n",
    "logf0_rmses_gt_array = np.array(logf0_rmses_gt)[~np.isnan(np.array(logf0_rmses_gt))]\n",
    "logf0_corrs_gt_array = np.array(logf0_corrs_gt)[~np.isnan(np.array(logf0_corrs_gt))]\n",
    "\n",
    "print(f\"logf0_rmse_gt mean on 0703b_1M2: {logf0_rmses_gt_array.mean()}\")\n",
    "print(f\"logf0_rmse_gt std on 0703b_1M2: {logf0_rmses_gt_array.std()}\")\n",
    "print(f\"logf0_corr_gt mean on 0703b_1M2: {logf0_corrs_gt_array.mean()}\")\n",
    "print(f\"logf0_corr_gt std on 0703b_1M2: {logf0_corrs_gt_array.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80f5f1-729d-4e39-93c3-0df7bc06bd30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
