{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec64649-3f37-43cf-abc8-a4f57690dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb9d106-ca37-4047-9a88-26f33c288ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407b6524-cc3d-4b49-ac91-5da4b1db4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.SubLayers import MultiHeadAttention, MultiHeadAttention_VariableQuery, PositionwiseFeedForward\n",
    "\n",
    "from transformer.Layers import FFTBlock, VisualFFTBlock\n",
    "\n",
    "from transformer.Models import VisualEncoder\n",
    "\n",
    "from utils.tools import get_mask_from_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f97e08b-00fa-456a-a690-c5e37d5a19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--restore_step\", type=int, default=0)\n",
    "parser.add_argument(\n",
    "    \"-p\",\n",
    "    \"--preprocess_config\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"path to preprocess.yaml\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-m\", \"--model_config\", type=str, required=True, help=\"path to model.yaml\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-t\", \"--train_config\", type=str, required=True, help=\"path to train.yaml\"\n",
    ")\n",
    "\n",
    "argString = '-p ./config/Ego4D_final_v6/0726b_preprocess.yaml -m ./config/Ego4D_final_v6/0726b_model.yaml -t ./config/Ego4D_final_v6/0726b_train.yaml'\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(argString.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893c493b-0949-457d-878e-012ad9b3c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import get_model, get_vocoder, get_param_num\n",
    "from utils.tools import to_device, log, synth_one_sample\n",
    "from model import FastSpeech2Loss\n",
    "from dataset import Dataset, VideoDataset\n",
    "from utils.auto_tqdm import tqdm\n",
    "from evaluate import evaluate\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eac12a7-7143-4fa7-87dd-0b39e92916d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(args.preprocess_config, \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# Read Config\n",
    "preprocess_config = yaml.load(\n",
    "    open(args.preprocess_config, \"r\"), Loader=yaml.FullLoader\n",
    ")\n",
    "model_config = yaml.load(open(args.model_config, \"r\"), Loader=yaml.FullLoader)\n",
    "train_config = yaml.load(open(args.train_config, \"r\"), Loader=yaml.FullLoader)\n",
    "configs = (preprocess_config, model_config, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae08e1f5-df7b-4c31-addf-052d2525b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare training ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Prepare training ...\")\n",
    "\n",
    "preprocess_config, model_config, train_config = configs\n",
    "# Get dataset\n",
    "dataset = VideoDataset(\n",
    "    \"train.txt\", 'train', preprocess_config, train_config, sort=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf9ca55-7f74-451f-b4f8-e586340a9a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27292"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae905eac-550f-4b6c-8fde-75aa1d2fc400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e5345b-a20b-4ecb-8fa6-24addb8ccb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_config[\"optimizer\"][\"batch_size\"]\n",
    "group_size = 4  # Set this larger than 1 to enable sorting in Dataset\n",
    "assert batch_size * group_size < len(dataset)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size * group_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e10e25-0342-4446-bc11-db1b20adb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return (\n",
    "#     ids,\n",
    "#     raw_texts,\n",
    "#     speakers,\n",
    "#     texts,\n",
    "#     text_lens,\n",
    "#     max(text_lens),\n",
    "#     mels,\n",
    "#     mel_lens,\n",
    "#     max(mel_lens),\n",
    "#     pitches,\n",
    "#     energies,\n",
    "#     durations,\n",
    "#     speaker_embeddings,\n",
    "#     video_embeddings,\n",
    "#     vid_lens,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2926ffc7-96ed-4de3-8b42-3911127a9c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Using speaker embeddings.\n",
      "=> Using VarianceAdaptorWithSpeaker.\n",
      "=> Using VisualEncoder.\n",
      "Using prosody vector for visual encoder.\n",
      "Successfully loaded from ./output/LibriTTS/LibriTTS_800000.pth.tar\n",
      "Number of FastSpeech2 Parameters: 55461233\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "model, optimizer = get_model(args, configs, device, train=True)\n",
    "model = nn.DataParallel(model)\n",
    "num_param = get_param_num(model)\n",
    "Loss = FastSpeech2Loss(preprocess_config, model_config).to(device)\n",
    "print(\"Number of FastSpeech2 Parameters:\", num_param)\n",
    "\n",
    "# Load vocoder\n",
    "vocoder = get_vocoder(model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed20600e-3ddd-4e79-a2fe-6adb1a21cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gpu_usage():\n",
    "    max_memory_allocated = torch.cuda.max_memory_allocated()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_properties = torch.cuda.get_device_properties(device)\n",
    "    available_memory = device_properties.total_memory - torch.cuda.max_memory_allocated()\n",
    "    message = \"\"\n",
    "    message += f\"Maximum GPU memory allocated by PyTorch: {max_memory_allocated / 1024**3:.2f} GB\\n\"\n",
    "    message += f\"Available GPU memory: {available_memory / 1024**3:.2f} GB\\n\"\n",
    "    print(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7ea48b4-9f8c-4388-998f-b677421d6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "step = args.restore_step + 1\n",
    "epoch = 1\n",
    "grad_acc_step = train_config[\"optimizer\"][\"grad_acc_step\"]\n",
    "grad_clip_thresh = train_config[\"optimizer\"][\"grad_clip_thresh\"]\n",
    "total_step = train_config[\"step\"][\"total_step\"]\n",
    "log_step = train_config[\"step\"][\"log_step\"]\n",
    "save_step = train_config[\"step\"][\"save_step\"]\n",
    "synth_step = train_config[\"step\"][\"synth_step\"]\n",
    "val_step = train_config[\"step\"][\"val_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79228f91-5172-4868-a162-59a070d92254",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in loader:\n",
    "    break\n",
    "item = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d14aaed-c5d7-457f-b192-41d88400e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_target = item[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c93ee81-c76f-4aad-8fb0-f9ef86ee3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_target = item[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d7f67b3-9fe1-4e0b-af0d-ed4c61470862",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_target = item[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d514bbfc-fde3-448a-a270-eee5f0c8f543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 116)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593d06f8-cd08-4554-8296-3b4a958d2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(values, durations):\n",
    "    out = list()\n",
    "    for value, d in zip(values, durations):\n",
    "        out += [value] * max(0, int(d))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e7e2e8c-d9a5-46fe-a570-8c66da195bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 15, 10, ...,  2, 48, 12],\n",
       "       [ 3,  3,  2, ...,  0,  0,  0],\n",
       "       [ 9,  9,  4, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 5, 25,  9, ...,  0,  0,  0],\n",
       "       [ 3,  6,  6, ...,  0,  0,  0],\n",
       "       [ 9, 30,  8, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9227e994-c3de-471d-8b39-b2839b7be6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch_extended = expand(pitch_target, duration_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23715d-5ea3-468f-9140-b496d84f1653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cb3d0-335d-493b-90ac-4051bff8cc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d037be7-a164-4ea6-ba78-7ef9a129b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch_target energy_target duration_target的长度为max text len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9a529e-15c9-4bdd-8b3d-4e4f5efb13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lens = item[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f7d492e-7bd6-4525-a26d-ba7a62d4ea2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116,  98,  90,  75,  72,  64,  49,  48,  41,  36,  35,  35,  34,\n",
       "        34,  33,  32,  32,  31,  30,  29,  28,  27,  27,  26])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "664740a6-294f-4ea3-b451-7def5a9a9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116,  98,  90,  75,  72,  64,  49,  48,  41,  36,  35,  35,  34,\n",
       "        34,  33,  32,  32,  31,  30,  29,  28,  27,  27,  26])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pitch_target!=0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6972c2a-88fa-41db-8523-59a1c6a60ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 116)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e60be3fe-95be-4676-a381-4e5b7a9632d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_input = nn.utils.rnn.pack_padded_sequence(\n",
    "#     p_predictions, \n",
    "#     lengths=text_lens, \n",
    "#     batch_first=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25f5852a-10bf-4487-9d0d-5a75bc2eb62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta\n",
      "delta\n",
      "delta\n",
      "delta\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batchs in enumerate(loader):\n",
    "    for batch in batchs:\n",
    "        batch = to_device(batch, device)\n",
    "        temp_batch = (batch[2:])\n",
    "        output = model(*(batch[2:]))\n",
    "    if batch_idx >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac2e0061-6072-420c-a316-d3d51323255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    output,\n",
    "    postnet_output,\n",
    "    p_predictions,\n",
    "    e_predictions,\n",
    "    log_d_predictions,\n",
    "    d_rounded,\n",
    "    src_masks,\n",
    "    mel_masks,\n",
    "    src_lens,\n",
    "    mel_lens,\n",
    ") = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "847ef41d-879b-4c9e-95c9-9deca7761d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57465e96-c37b-49b7-877c-53bfa664dd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f86a2a6-ca6a-41b7-9743-3c5f70c3dae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fd67486-c7f6-418b-8b1c-ca9e2f92dfbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pitch \u001b[38;5;241m=\u001b[39m p_predictions[\u001b[38;5;241m0\u001b[39m, :\u001b[43msrc_len\u001b[49m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'src_len' is not defined"
     ]
    }
   ],
   "source": [
    "pitch = p_predictions[0, :src_len].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2a241-85c9-48c2-9f09-4496878282ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eaae0-1157-4f64-b176-f58af5e865aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input = nn.utils.rnn.pack_padded_sequence(\n",
    "    p_predictions, \n",
    "    lengths=src_lens.cpu(), \n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f5217-490d-4bd8-a636-394e7bb2d7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49affe-a4d4-41cf-b778-1b5d9d318f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e972574-f6a7-479d-88dc-688ecd92e07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd358c-af04-4013-8a30-497d381f0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4da60b-a63c-4228-bc78-cc5d49636d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f76b9-79b9-453a-b8e6-04792142f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_d_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b423d74-00e2-49d0-8668-184af6a9f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_d_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058085b-cc42-42ae-b917-6a40d0f6199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708ae35-f7ac-4871-99c2-bf4a8ead32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log_gpu_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
