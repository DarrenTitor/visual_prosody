{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903dcbd0-d9ba-47f3-9a91-131ca0b861a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\Schoolwork\\TERM 3\\WORK\\visual_prosody\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4bb692-815f-4697-a1d2-4f6f8f8bf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil\n",
    "import os.path as op\n",
    "import argparse\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import os.path as op\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50b7dbd-38e8-4856-bceb-6188857ca56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import fnmatch\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import librosa\n",
    "import pysptk\n",
    "import pyworld as pw\n",
    "import soundfile as sf\n",
    "from fastdtw import fastdtw\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526f10b7-0a9a-4905-a5f2-97daea986c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt_val_path = r'.\\preprocessed_data\\LJSpeech\\val.txt'\n",
    "val_uids = []\n",
    "with open(split_txt_val_path) as file:\n",
    "    for line in file:\n",
    "        # print(line.split('|')[0])\n",
    "        val_uids.append(line.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65ae6be-ae95-47dc-acd7-eff9003998b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de9448-7139-4d05-865f-cf041eb46fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009ae216-5566-41e2-bd9f-2f03680b5811",
   "metadata": {},
   "source": [
    "# MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588a768f-d61c-4fa0-80ca-2409831cf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_folder = r'.\\output\\0629lj\\result\\LJSpeech\\wav\\reconstructed'\n",
    "syn_folder = r'.\\output\\0629lj\\result\\LJSpeech\\wav\\synthesized'\n",
    "gt_folder = r'.\\Data\\LJSpeech-1.1\\wavs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6875d246-1374-4a83-9a6c-62efd2e7d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "melkwargs = {\n",
    "    \"n_fft\": int(0.05 * sr), \"win_length\": int(0.05 * sr),\n",
    "    \"hop_length\": int(0.0125 * sr), \"f_min\": 20,\n",
    "    \"n_mels\": 80, \"window_fn\": torch.hann_window\n",
    "}\n",
    "mfcc_fn = torchaudio.transforms.MFCC(\n",
    "    sr, n_mfcc=13, log_mels=True, melkwargs=melkwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7773c0-2850-439f-936e-bb06fe450f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b823f42c912b4a8088bc665a7043d66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uids = []\n",
    "MCDs_recon = []\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    wav_1, sr = torchaudio.load(op.join(recon_folder, f\"{uid}.wav\"))\n",
    "    wav_2, sr = torchaudio.load(op.join(syn_folder, f\"{uid}.wav\"))\n",
    "    wav_1 = wav_1.squeeze()\n",
    "    wav_2 = wav_2.squeeze()\n",
    "    mel_1 = mfcc_fn(wav_1).T.numpy()\n",
    "    mel_2 = mfcc_fn(wav_2).T.numpy()\n",
    "    # DTW\n",
    "    _, path = fastdtw(mel_2, mel_1, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    mel_2 = mel_2[twf[0]]\n",
    "    mel_1 = mel_1[twf[1]]\n",
    "    # We sum the squared differences over the first K MFCCs, skipping ct,0\n",
    "    mel_1 = mel_1[:, 1:]\n",
    "    mel_2 = mel_2[:, 1:]\n",
    "    result = (((mel_1 - mel_2) ** 2).sum(axis=1)**0.5).mean()\n",
    "    MCDs_recon.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f460f50f-fe50-46df-8f2c-e78d40b201d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bde2dd4f484e7cac842dc3aa8b884e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uids = []\n",
    "MCDs_gt = []\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    wav_1, sr = torchaudio.load(op.join(gt_folder, f\"{uid}.wav\"))\n",
    "    wav_2, sr = torchaudio.load(op.join(syn_folder, f\"{uid}.wav\"))\n",
    "    wav_1 = wav_1.squeeze()\n",
    "    wav_2 = wav_2.squeeze()\n",
    "    mel_1 = mfcc_fn(wav_1).T.numpy()\n",
    "    mel_2 = mfcc_fn(wav_2).T.numpy()\n",
    "    # DTW\n",
    "    _, path = fastdtw(mel_2, mel_1, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    mel_2 = mel_2[twf[0]]\n",
    "    mel_1 = mel_1[twf[1]]\n",
    "    # We sum the squared differences over the first K MFCCs, skipping ct,0\n",
    "    mel_1 = mel_1[:, 1:]\n",
    "    mel_2 = mel_2[:, 1:]\n",
    "    result = (((mel_1 - mel_2) ** 2).sum(axis=1)**0.5).mean()\n",
    "    MCDs_gt.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b216ea-fcfb-46eb-a7fa-41d9f656507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_mcd_df = pd.DataFrame({\n",
    "    'uid': uids,\n",
    "    'MCD_recon': MCDs_recon,\n",
    "    'MCD_gt': MCDs_gt,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932b6603-470c-44c0-a997-f9166464154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_mcd_df.to_csv(r\".\\jupyter_walkthrough\\metrics\\MCD_LJ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1d69f4-3b91-4057-9675-0d23c0c312cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDs_recon mean on LJSpeech: 5.480271339416504\n",
      "MCDs_recon std on LJSpeech: 0.7322819232940674\n",
      "MCDs_gt mean on LJSpeech: 7.159063339233398\n",
      "MCDs_gt std on LJSpeech: 0.9118814468383789\n"
     ]
    }
   ],
   "source": [
    "print(f\"MCDs_recon mean on LJSpeech: {torch.tensor(MCDs_recon).mean()}\")\n",
    "print(f\"MCDs_recon std on LJSpeech: {torch.tensor(MCDs_recon).std()}\")\n",
    "\n",
    "print(f\"MCDs_gt mean on LJSpeech: {torch.tensor(MCDs_gt).mean()}\")\n",
    "print(f\"MCDs_gt std on LJSpeech: {torch.tensor(MCDs_gt).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598c7ff-3c48-4140-8f12-0fbd82a160be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ffa0bf2-b990-4654-8eb2-1906a1b464b3",
   "metadata": {},
   "source": [
    "# log f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56b008b-f2ba-42ab-9ee6-a26210fb5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/espnet/espnet/blob/3e0dad524d62ccd45e067e9b36049f2214ea972a/egs2/TEMPLATE/asr1/pyscripts/utils/evaluate_f0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8319551b-190e-4ca0-ab80-37d98da92a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_extract(\n",
    "    x: np.ndarray,\n",
    "    fs: int,\n",
    "    f0min: int = 40,\n",
    "    f0max: int = 800,\n",
    "    n_fft: int = 512,\n",
    "    n_shift: int = 256,\n",
    "    mcep_dim: int = 25,\n",
    "    mcep_alpha: float = 0.41,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Extract World-based acoustic features.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): 1D waveform array.\n",
    "        fs (int): Minimum f0 value (default=40).\n",
    "        f0 (int): Maximum f0 value (default=800).\n",
    "        n_shift (int): Shift length in point (default=256).\n",
    "        n_fft (int): FFT length in point (default=512).\n",
    "        n_shift (int): Shift length in point (default=256).\n",
    "        mcep_dim (int): Dimension of mel-cepstrum (default=25).\n",
    "        mcep_alpha (float): All pass filter coefficient (default=0.41).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Mel-cepstrum with the size (N, n_fft).\n",
    "        ndarray: F0 sequence (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # extract features\n",
    "    x = x.astype(np.float64)\n",
    "    f0, time_axis = pw.harvest(\n",
    "        x,\n",
    "        fs,\n",
    "        f0_floor=f0min,\n",
    "        f0_ceil=f0max,\n",
    "        frame_period=n_shift / fs * 1000,\n",
    "    )\n",
    "    sp = pw.cheaptrick(x, f0, time_axis, fs, fft_size=n_fft)\n",
    "    if mcep_dim is None or mcep_alpha is None:\n",
    "        mcep_dim, mcep_alpha = _get_best_mcep_params(fs)\n",
    "    mcep = pysptk.sp2mc(sp, mcep_dim, mcep_alpha)\n",
    "\n",
    "    return mcep, f0\n",
    "\n",
    "\n",
    "def _get_basename(path: str) -> str:\n",
    "    return os.path.splitext(os.path.split(path)[-1])[0]\n",
    "\n",
    "\n",
    "def _get_best_mcep_params(fs: int) -> Tuple[int, float]:\n",
    "    if fs == 16000:\n",
    "        return 23, 0.42\n",
    "    elif fs == 22050:\n",
    "        return 34, 0.45\n",
    "    elif fs == 24000:\n",
    "        return 34, 0.46\n",
    "    elif fs == 44100:\n",
    "        return 39, 0.53\n",
    "    elif fs == 48000:\n",
    "        return 39, 0.55\n",
    "    else:\n",
    "        raise ValueError(f\"Not found the setting for {fs}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94dc3fd1-32cc-40a6-ab1d-60db1f120ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b5ccf8193d4ea89788fbcbd45d04c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uids = []\n",
    "logf0_rmses_recon = []\n",
    "logf0_corrs_recon = []\n",
    "\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    # load wav file as int16\n",
    "    gen_x, gen_fs = sf.read(op.join(syn_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    gt_x, gt_fs = sf.read(op.join(recon_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    fs = gen_fs\n",
    "    # extract ground truth and converted features\n",
    "    gen_mcep, gen_f0 = world_extract(\n",
    "        x=gen_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    gt_mcep, gt_f0 = world_extract(\n",
    "        x=gt_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    \n",
    "    # DTW\n",
    "    _, path = fastdtw(gen_mcep, gt_mcep, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    gen_f0_dtw = gen_f0[twf[0]]\n",
    "    gt_f0_dtw = gt_f0[twf[1]]\n",
    "    \n",
    "    # Get voiced part\n",
    "    nonzero_idxs = np.where((gen_f0_dtw != 0) & (gt_f0_dtw != 0))[0]\n",
    "    gen_f0_dtw_voiced = np.log(gen_f0_dtw[nonzero_idxs])\n",
    "    gt_f0_dtw_voiced = np.log(gt_f0_dtw[nonzero_idxs])\n",
    "\n",
    "    # log F0 RMSE\n",
    "    log_f0_rmse = np.sqrt(np.mean((gen_f0_dtw_voiced - gt_f0_dtw_voiced) ** 2))\n",
    "    # print(f\"{uid} {log_f0_rmse:.4f}\")\n",
    "\n",
    "    # log F0 corr\n",
    "    log_f0_corr = np.corrcoef(gen_f0_dtw_voiced, gt_f0_dtw_voiced)[0][1]\n",
    "    # print(f\"{uid} {log_f0_corr:.4f}\")\n",
    "\n",
    "    logf0_rmses_recon.append(log_f0_rmse)\n",
    "    logf0_corrs_recon.append(log_f0_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b81479f-8f60-44f0-a28d-de0c3ec8d2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aed98417964b0e912aaa80034ace58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uids = []\n",
    "logf0_rmses_gt = []\n",
    "logf0_corrs_gt = []\n",
    "\n",
    "for uid in tqdm(val_uids):\n",
    "    uids.append(uid)\n",
    "    # load wav file as int16\n",
    "    gen_x, gen_fs = sf.read(op.join(syn_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    gt_x, gt_fs = sf.read(op.join(gt_folder, f\"{uid}.wav\"), dtype=\"int16\")\n",
    "    fs = gen_fs\n",
    "    # extract ground truth and converted features\n",
    "    gen_mcep, gen_f0 = world_extract(\n",
    "        x=gen_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    gt_mcep, gt_f0 = world_extract(\n",
    "        x=gt_x,\n",
    "        fs=fs,\n",
    "        f0min=40,\n",
    "        f0max=800,\n",
    "        n_fft=1024,\n",
    "        n_shift=256,\n",
    "        mcep_dim=None,\n",
    "        mcep_alpha=None,\n",
    "    )\n",
    "    \n",
    "    # DTW\n",
    "    _, path = fastdtw(gen_mcep, gt_mcep, dist=spatial.distance.euclidean)\n",
    "    twf = np.array(path).T\n",
    "    gen_f0_dtw = gen_f0[twf[0]]\n",
    "    gt_f0_dtw = gt_f0[twf[1]]\n",
    "    \n",
    "    # Get voiced part\n",
    "    nonzero_idxs = np.where((gen_f0_dtw != 0) & (gt_f0_dtw != 0))[0]\n",
    "    gen_f0_dtw_voiced = np.log(gen_f0_dtw[nonzero_idxs])\n",
    "    gt_f0_dtw_voiced = np.log(gt_f0_dtw[nonzero_idxs])\n",
    "\n",
    "    # log F0 RMSE\n",
    "    log_f0_rmse = np.sqrt(np.mean((gen_f0_dtw_voiced - gt_f0_dtw_voiced) ** 2))\n",
    "    # print(f\"{uid} {log_f0_rmse:.4f}\")\n",
    "\n",
    "    # log F0 corr\n",
    "    log_f0_corr = np.corrcoef(gen_f0_dtw_voiced, gt_f0_dtw_voiced)[0][1]\n",
    "    # print(f\"{uid} {log_f0_corr:.4f}\")\n",
    "\n",
    "    logf0_rmses_gt.append(log_f0_rmse)\n",
    "    logf0_corrs_gt.append(log_f0_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2020778a-5b4d-4ecd-8ee3-f0612f704a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_logf0_df = pd.DataFrame({\n",
    "    'uid': uids,\n",
    "    'logf0_rmse_recon': logf0_rmses_recon,\n",
    "    'logf0_corr_recon': logf0_corrs_recon,\n",
    "    'logf0_rmse_gt': logf0_rmses_gt,\n",
    "    'logf0_corr_gt': logf0_corrs_gt,\n",
    "})\n",
    "lj_logf0_df.to_csv(r\".\\jupyter_walkthrough\\metrics\\logF0_LJ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f060a-3869-46c2-98a0-8d677bd5d26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27aef99f-04cc-4e07-b493-4cbf1b7314b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logf0_rmse_recon mean on LJSpeech: 0.2128476233348171\n",
      "logf0_rmse_recon std on LJSpeech: 0.07755068307229493\n",
      "logf0_corr_recon mean on LJSpeech: 0.7322283435658924\n",
      "logf0_corr_recon std on LJSpeech: 0.16015679184393214\n",
      "logf0_rmse_gt mean on LJSpeech: 0.2078816564710602\n",
      "logf0_rmse_gt std on LJSpeech: 0.08039552050371225\n",
      "logf0_corr_gt mean on LJSpeech: 0.7355830529558801\n",
      "logf0_corr_gt std on LJSpeech: 0.14026441509413443\n"
     ]
    }
   ],
   "source": [
    "print(f\"logf0_rmse_recon mean on LJSpeech: {torch.tensor(logf0_rmses_recon).mean()}\")\n",
    "print(f\"logf0_rmse_recon std on LJSpeech: {torch.tensor(logf0_rmses_recon).std()}\")\n",
    "print(f\"logf0_corr_recon mean on LJSpeech: {torch.tensor(logf0_corrs_recon).mean()}\")\n",
    "print(f\"logf0_corr_recon std on LJSpeech: {torch.tensor(logf0_corrs_recon).std()}\")\n",
    "\n",
    "print(f\"logf0_rmse_gt mean on LJSpeech: {torch.tensor(logf0_rmses_gt).mean()}\")\n",
    "print(f\"logf0_rmse_gt std on LJSpeech: {torch.tensor(logf0_rmses_gt).std()}\")\n",
    "print(f\"logf0_corr_gt mean on LJSpeech: {torch.tensor(logf0_corrs_gt).mean()}\")\n",
    "print(f\"logf0_corr_gt std on LJSpeech: {torch.tensor(logf0_corrs_gt).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7668d2a-027a-4512-b2ea-85ba53992573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82951ce-c580-4e68-bb0a-e5f2a421ea96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64837b-3a91-4eb0-bda0-1eea554ba7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d9f7e-50f4-42af-ba32-452b0f2d01bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f3c02-b2af-4958-b1a9-5b2f699887f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea508e-3c81-4106-9b79-c870a36ef6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18843907-82a2-4a08-be33-d89bea6e63cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e6ec8-757c-4fc1-8139-42f092e16e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520468da-89a0-49ed-a9ee-dc76ed5239aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d8b3b-07e0-4e1d-803a-489f491c20df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fe190-61ec-4812-b7f7-1cbf91a04f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694157d-2395-4974-8623-3e0cfbbfbb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2754ed-bff1-4b05-a06d-6b17c518b7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c79930-ce4d-49d8-9617-1f6287001357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94b05e-1443-436b-84bc-ee337a6d508a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e6ee3-4f2c-40af-8d8a-b401df58cbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cde19e-b176-4f7f-b98d-efae5ecc590a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db1c16-00da-4843-b920-eebc29b21625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5d167-134a-4dec-b0ca-d00deaaf9e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c9089-82e7-440b-b611-e247abe8f739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd2be7-e1e5-4790-82ab-7ca38044703a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b49a74-af79-4dff-803f-20b062eeeaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716bf98-7eb7-4404-8299-bfc4e8c25a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
